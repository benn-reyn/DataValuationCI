import pandas as pd
import numpy as np
from pathlib import Path
import textwrap
import math

# Load the uploaded CSV
path = Path("/mnt/data/lawsuit_data_leakages.csv")
df = pd.read_csv(path)

# Show the first few rows and the columns to the user
import caas_jupyter_tools as cj
cj.display_dataframe_to_user("Raw lawsuit/leak dataset (preview)", df.head(50))

# Build a simple relevance rubric for BMW risk/valuation
# Heuristics using common column names; we'll adapt if names differ.

cols = {c.lower(): c for c in df.columns}

# Helper getters with safe fallbacks
def g(row, key_like, default=None):
    # find a column whose lowercase name contains key_like
    for k, orig in cols.items():
        if key_like in k:
            return row[orig]
    return default

def contains_any(text, keywords):
    if not isinstance(text, str):
        text = "" if pd.isna(text) else str(text)
    tl = text.lower()
    return any(k.lower() in tl for k in keywords)

# Define weights (tweakable)
W = {
    "industry": 3.0,
    "geography": 2.0,
    "data_type": 3.0,
    "scale": 2.0,
    "regulatory": 2.5,
    "recency": 1.5,
    "outcome": 2.0
}

def score_row(row):
    score = 0.0
    reasons = []

    # Industry relevance
    industry = g(row, "industry") or g(row, "sector") or ""
    if contains_any(industry, ["automotive","auto","manufactur","industrial","robot","mobility","transport"]):
        score += W["industry"]; reasons.append("Industry matches (automotive/manufacturing)")
    elif contains_any(industry, ["technology","retail","finance","health","insurance"]):
        score += W["industry"]*0.5; reasons.append("Adjacent industry")

    # Geography relevance
    country = (g(row, "country") or g(row, "region") or g(row, "jurisdiction") or "")
    if contains_any(country, ["germany","eu","europe","european","spartanburg","us","united states","south carolina","uk","ireland"]):
        score += W["geography"]; reasons.append("Relevant geography (EU/US)")

    # Data type relevance
    dtype = (g(row, "data_type") or g(row, "data category") or g(row, "what was leaked") or g(row, "description") or "")
    if contains_any(dtype, ["pii","personal","employee","customer","credential","email","ssn","address"]):
        score += W["data_type"]*0.7; reasons.append("PII implications (GDPR/CCPA risk)")
    if contains_any(dtype, ["ip","trade secret","design","cad","source code","process","telemetry","operational","oee","production","supplier"]):
        score += W["data_type"]; reasons.append("Operational/IP data relevant to plant ops")

    # Scale (records count)
    records = g(row, "records") or g(row, "affected") or g(row, "users") or g(row, "size")
    try:
        # Try to parse numeric from string with commas
        rnum = float(str(records).replace(",","").split()[0])
    except Exception:
        rnum = np.nan
    if not math.isnan(rnum):
        if rnum >= 1_000_000:
            score += W["scale"]; reasons.append("Large-scale breach (≥1M)")
        elif rnum >= 100_000:
            score += W["scale"]*0.6; reasons.append("Medium-scale breach (≥100k)")

    # Regulatory involvement / fines
    reg = (g(row, "fine") or g(row, "penalty") or g(row, "regulator") or g(row, "legal") or "")
    if contains_any(str(reg), ["gdpr","ico","cnil","bafin","fcc","ftc","ccpa","cpa","edpb","bsi"]):
        score += W["regulatory"]; reasons.append("Regulatory action (GDPR/US)")

    # Outcome amount (settlement / damages)
    amt = g(row, "settlement") or g(row, "damages") or g(row, "amount")
    try:
        anum = float(str(amt).replace("$","").replace(",","").split()[0])
    except Exception:
        anum = np.nan
    if not math.isnan(anum):
        if anum >= 10_000_000:
            score += W["outcome"]; reasons.append("High damages/settlement (≥$10M)")
        elif anum >= 1_000_000:
            score += W["outcome"]*0.6; reasons.append("Notable damages (≥$1M)")

    # Recency (year)
    year = g(row, "year") or g(row, "date") or g(row, "reported")
    yscore = 0.0
    try:
        y = int(str(year)[:4])
        if y >= 2023:
            yscore = W["recency"]
            reasons.append("Recent case (2023+)")
        elif y >= 2020:
            yscore = W["recency"]*0.6
            reasons.append("Fairly recent (2020–2022)")
    except Exception:
        pass
    score += yscore

    return score, "; ".join(reasons)

scores = []
for idx, row in df.iterrows():
    s, why = score_row(row)
    scores.append((s, why))

df_out = df.copy()
df_out["relevance_score_0_15"] = [round(min(15.0, s), 2) for s, _ in scores]
df_out["reasoning"] = [w for _, w in scores]

# Rank by score
df_ranked = df_out.sort_values("relevance_score_0_15", ascending=False).reset_index(drop=True)

# Show to user
import caas_jupyter_tools as cj
cj.display_dataframe_to_user("Relevance-ranked cases for BMW data leakage modeling", df_ranked)

# Provide a compact top-10 summary
top10 = df_ranked.head(10)[[c for c in df_ranked.columns if c.lower() in ["case","title","company","industry","country","year","relevance_score_0_15","reasoning"] or "case" in c.lower() or "name" in c.lower()]]
cj.display_dataframe_to_user("Top 10 cases — quick view", top10)

"Analysis complete. Two tables were opened for you: full ranked list and Top 10."
import pandas as pd, numpy as np, math
from pathlib import Path
import caas_jupyter_tools as cj

# Load CSV
path = Path("/mnt/data/lawsuit_data_leakages.csv")
df = pd.read_csv(path)

# Preview for the user
cj.display_dataframe_to_user("Raw lawsuit/leak dataset (first 50 rows)", df.head(50))

# Normalize column lookup
cols = {c.lower(): c for c in df.columns}

def col_like(key):
    for k, orig in cols.items():
        if key in k:
            return orig
    return None

def contains_any(text, keywords):
    if not isinstance(text, str):
        text = "" if pd.isna(text) else str(text)
    tl = text.lower()
    return any(k.lower() in tl for k in keywords)

def get(row, key, alt_keys=[]):
    c = col_like(key)
    if c is not None:
        return row[c]
    for ak in alt_keys:
        c = col_like(ak)
        if c is not None:
            return row[c]
    return None

W = dict(industry=3.0, geography=2.0, data_type=3.0, scale=2.0, regulatory=2.5, recency=1.5, outcome=2.0)

def score_row(row):
    score, why = 0.0, []

    industry = get(row, "industry") or get(row, "sector") or ""
    if contains_any(industry, ["automotive","auto","manufactur","industrial","robot","mobility","transport"]):
        score += W["industry"]; why.append("Industry match (automotive/manufacturing)")
    elif contains_any(industry, ["technology","retail","finance","health","insurance","utilities"]):
        score += W["industry"]*0.5; why.append("Adjacent industry")

    geo = get(row, "country") or get(row, "region") or get(row, "jurisdiction") or ""
    if contains_any(geo, ["germany","eu","europe","united states","us","spartanburg","south carolina","uk","ireland"]):
        score += W["geography"]; why.append("Relevant geography (EU/US)")

    dtype = get(row, "data_type") or get(row, "category") or get(row, "what") or get(row, "description") or ""
    if contains_any(dtype, ["pii","personal","employee","customer","credential","email","ssn","address","hr"]):
        score += W["data_type"]*0.7; why.append("PII (GDPR/CCPA exposure)")
    if contains_any(dtype, ["ip","trade secret","design","cad","source code","process","telemetry","operational","oee","production","supplier"]):
        score += W["data_type"]; why.append("Operational/IP data (plant ops relevance)")

    records = get(row, "records") or get(row, "affected") or get(row, "users") or get(row, "size")
    try:
        rnum = float(str(records).replace(",","").split()[0])
        if rnum >= 1_000_000: score += W["scale"]; why.append("Large-scale (≥1M)")
        elif rnum >= 100_000: score += W["scale"]*0.6; why.append("Medium-scale (≥100k)")
    except Exception:
        pass

    reg = (get(row, "fine") or get(row, "penalty") or get(row, "regulator") or get(row, "legal") or "")
    if contains_any(str(reg), ["gdpr","ico","cnil","bafin","ftc","ccpa","edpb","bsi"]):
        score += W["regulatory"]; why.append("Regulatory action")

    amt = get(row, "settlement") or get(row, "damages") or get(row, "amount")
    try:
        anum = float(str(amt).replace("$","").replace(",","").split()[0])
        if anum >= 10_000_000: score += W["outcome"]; why.append("High damages/settlement (≥$10M)")
        elif anum >= 1_000_000: score += W["outcome"]*0.6; why.append("Notable damages (≥$1M)")
    except Exception:
        pass

    year = get(row, "year") or get(row, "date") or get(row, "reported")
    try:
        y = int(str(year)[:4])
        if y >= 2023: score += W["recency"]; why.append("Recent (2023+)")
        elif y >= 2020: score += W["recency"]*0.6; why.append("Fairly recent (2020–2022)")
    except Exception:
        pass

    return min(15.0, round(score,2)), "; ".join(why)

scores, reasons = [], []
for _, row in df.iterrows():
    s, r = score_row(row)
    scores.append(s); reasons.append(r)

out = df.copy()
out["relevance_score_0_15"] = scores
out["reasoning"] = reasons

ranked = out.sort_values("relevance_score_0_15", ascending=False).reset_index(drop=True)
cj.display_dataframe_to_user("Ranked relevance (top first) — with reasoning", ranked)

# Top-10 compact view
keep_cols = []
for c in df.columns:
    cl = c.lower()
    if any(k in cl for k in ["case","title","name","company","industry","country","year","date"]):
        keep_cols.append(c)
# always include these
keep_cols += ["relevance_score_0_15","reasoning"]
top10 = ranked.loc[:9, keep_cols]
cj.display_dataframe_to_user("Top 10 cases — compact view", top10)

"Done."
=MIN(15,
  /* Industry (0–3) */
  IF(OR(ISNUMBER(SEARCH("auto",A2)),ISNUMBER(SEARCH("manufactur",A2)),ISNUMBER(SEARCH("industrial",A2)),ISNUMBER(SEARCH("robot",A2))),3,
     IF(OR(ISNUMBER(SEARCH("mobility",A2)),ISNUMBER(SEARCH("logistic",A2)),ISNUMBER(SEARCH("supplier",A2))),1.5,0))
  +
  /* Geography (0–2) */
  IF(OR(ISNUMBER(SEARCH("germany",B2)),ISNUMBER(SEARCH("eu",B2)),ISNUMBER(SEARCH("europe",B2)),
        ISNUMBER(SEARCH("united states",B2)),ISNUMBER(SEARCH("us",B2)),ISNUMBER(SEARCH("uk",B2))),2, IF(B2<>"",1,0))
  +
  /* Data type (0–3 cap) — PII + Ops/IP */
  MIN(3,
    IF(OR(ISNUMBER(SEARCH("ip",C2)),ISNUMBER(SEARCH("trade secret",C2)),ISNUMBER(SEARCH("cad",C2)),
          ISNUMBER(SEARCH("process",C2)),ISNUMBER(SEARCH("oee",C2)),ISNUMBER(SEARCH("telemetry",C2)),
          ISNUMBER(SEARCH("production",C2)),ISNUMBER(SEARCH("supplier",C2))),3,0)
    +
    IF(OR(ISNUMBER(SEARCH("pii",C2)),ISNUMBER(SEARCH("personal",C2)),ISNUMBER(SEARCH("employee",C2)),
          ISNUMBER(SEARCH("customer",C2)),ISNUMBER(SEARCH("credential",C2)),ISNUMBER(SEARCH("email",C2))),1,0)
  )
  +
  /* Scale (0–2) */
  IFERROR(IF(VALUE(SUBSTITUTE(D2,",",""))>=1000000,2, IF(VALUE(SUBSTITUTE(D2,",",""))>=100000,1.2,0)),0)
  +
  /* Regulatory (0–2.5) */
  IF(OR(ISNUMBER(SEARCH("gdpr",E2)),ISNUMBER(SEARCH("ico",E2)),ISNUMBER(SEARCH("cnil",E2)),
        ISNUMBER(SEARCH("ftc",E2)),ISNUMBER(SEARCH("ccpa",E2)),ISNUMBER(SEARCH("edpb",E2)),ISNUMBER(SEARCH("bsi",E2))),2.5,
     IF(E2<>"",1,0))
  +
  /* Recency (0–1.5) */
  IFERROR(IF(VALUE(LEFT(F2,4))>=2023,1.5, IF(VALUE(LEFT(F2,4))>=2020,0.9,0)),0)
  +
  /* Outcome amount (0–2) */
  IFERROR(IF(VALUE(SUBSTITUTE(SUBSTITUTE(G2,"$",""),",",""))>=10000000,2,
            IF(VALUE(SUBSTITUTE(SUBSTITUTE(G2,"$",""),",",""))>=1000000,1.2,0)),0)
)

